{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The focal repository is projectblacklight/blacklight\n",
      "The number of contributors are 4\n",
      "The number of core contributors are 1\n",
      "The Subsequent work citing both the references and the focal repository are ['projecthydra/solrizer', 'projecthydra/hydra-head', 'projecthydra/jettywrapper']\n",
      "The length of the actors are24206\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ee364691be45df8e250376096eb5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=24206.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_disruption_value(focal_repository):\n",
    "    \n",
    "    \n",
    "    # Get the data for the the focal repository only\n",
    "    query='SELECT * FROM gitdatam WHERE repo_name = %s'\n",
    "    df = pd.read_sql(query, con=db, params=[focal_repository])\n",
    "    # pass the dataframe into the fuction containing all the types pertaining to one repository\n",
    "    def contributors_fun(df):\n",
    "        Contributors=[]\n",
    "        Contributors=df.loc[(df['type']==\"PullRequestEvent\")&(df['payload_pull_request_merged']==\"TRUE\")].actor_login.tolist()\n",
    "        unique_contributors= set(Contributors)\n",
    "        return unique_contributors\n",
    "\n",
    "\n",
    "    #calling function to get the contributors to a repository\n",
    "    contributors=contributors_fun(df)\n",
    "\n",
    "\n",
    "    #print contributors\n",
    "    #print(\"The contributors for the focal repository are {}\".format(contributors))\n",
    "    print(\"The focal repository is {}\".format(focal_repository))\n",
    "    print(\"The number of contributors are {0}\".format(len(contributors)))\n",
    "    if len(contributors)==0:\n",
    "        D=\"NaN\"\n",
    "        Parameters=[D,len(contributors)]\n",
    "        return Parameters\n",
    "    else:\n",
    "\n",
    "\n",
    "        #function to find core-contributors\n",
    "        #pass the dataframe consisting only the records of repository for which you want to find the core contributors\n",
    "        #useful function if you have a single repository and a list of unique contributors\n",
    "        def core_contributors_fun(unique_contributors,Main_df):\n",
    "            #Showing the push events by all the contributors to dynamo-easy repository by putting them in a dataframe\n",
    "            Contributors_df=pd.DataFrame()\n",
    "            Contributors_df=Main_df.loc[(df['type']==\"PushEvent\")&(Main_df.actor_login.isin(unique_contributors))].copy()\n",
    "            # forming a dictionary of count of each contributor as the value and contributor as key.\n",
    "            from collections import defaultdict\n",
    "            contributors_push_count = defaultdict(list)\n",
    "            temp_list=[]\n",
    "            for key in unique_contributors:\n",
    "                temp_list.append(key)\n",
    "                contributors_push_count[key]=Contributors_df.actor_login.isin(temp_list).sum()\n",
    "                temp_list.pop()\n",
    "\n",
    "            #finding out the number of pushes of all the contributors for dynamo-easy repository\n",
    "            Total_pushes_count=Contributors_df.id.count()\n",
    "\n",
    "            #Average of all the pushes by the contributors\n",
    "            Average_pushes=Total_pushes_count/len(unique_contributors)\n",
    "\n",
    "            #Compare the average number of pushes of all the contributors to number of pushes to individual contributors in \n",
    "            #unique contributors list\n",
    "            Core_contributors=[]\n",
    "            for key,value in contributors_push_count.items():\n",
    "                if value > Average_pushes:\n",
    "                    Core_contributors.append(key)\n",
    "            return Core_contributors\n",
    "\n",
    "\n",
    "    #calling the function to get core-contributors\n",
    "        core_contributors_main=core_contributors_fun(contributors,df)\n",
    "        #print(\"The core-contributors to the focal repository are {}\".format(core_contributors_main))\n",
    "        print(\"The number of core contributors are {0}\".format(len(core_contributors_main)))\n",
    "\n",
    "\n",
    "        #function to get the references for the current repositories\n",
    "        #pass the core contributors and the data frame consisting all types of entries.\n",
    "        def reference_repos(Core_contributors,Main_df,core_df_all):\n",
    "\n",
    "            # making a data frame which has only the core-contributors\n",
    "            core_df=Main_df[Main_df.actor_login.isin(Core_contributors)]\n",
    "            time_df = pd.DataFrame(columns=['core_contributors','start_date','end_date'])\n",
    "            #core_df.groupby('actor_id').groups\n",
    "            grouped = core_df.groupby('actor_login')\n",
    "            for name,group in grouped:\n",
    "                dict_row={'core_contributors':name,'start_date':group.created_at.min(),'end_date':group.created_at.max()}\n",
    "                time_df=time_df.append(dict_row,ignore_index=True)\n",
    "            Final_Repositories=[]\n",
    "\n",
    "            for index,row in time_df.iterrows():\n",
    "                row_start_date=row['start_date']\n",
    "                row_end_date=row['end_date']\n",
    "                Final_Repositories.extend(core_df_all.loc[(core_df_all['actor_login']==row['core_contributors'])&(core_df_all.created_at.between(row_start_date,row_end_date))&(core_df_all.type==\"ForkEvent\")].repo_name)\n",
    "            return list(set(Final_Repositories))\n",
    "\n",
    "\n",
    "\n",
    "        #Getting the dataframe consisting of all repositories related to the core-contributors\n",
    "        if len(core_contributors_main)==0:\n",
    "            D=\"NaN\"\n",
    "            Parameters=[D,len(contributors),len(core_contributors_main)]\n",
    "            return Parameters\n",
    "        else:\n",
    "            if len(core_contributors_main)==1:\n",
    "                query = 'SELECT * FROM gitdatam WHERE actor_login = %s '\n",
    "                core_df_all = pd.read_sql(query, con=db,params=[core_contributors_main[0]])\n",
    "\n",
    "            else:\n",
    "                core_contributors_t = tuple(core_contributors_main)\n",
    "                query = \"SELECT * FROM gitdatam WHERE actor_login IN {}\".format(core_contributors_t)\n",
    "                core_df_all = pd.read_sql(query, con=db)\n",
    "            core_df_all.head()\n",
    "\n",
    "\n",
    "            #calling the function to get the reference repositories\n",
    "            reference_repos_list=reference_repos(core_contributors_main,df,core_df_all)\n",
    "            if len(reference_repos_list)==0:\n",
    "                D=\"NaN\"\n",
    "                Parameters=[D,len(contributors),len(core_contributors_main)]\n",
    "                return Parameters\n",
    "    \n",
    "\n",
    "            #printing reference repos\n",
    "            #print(\"The reference repos for the focal repository are : {}\".format(reference_repos_list))\n",
    "\n",
    "\n",
    "\n",
    "            #calling function to get the contributors to the focal repository\n",
    "\n",
    "            #print(\"The contributors to the focal repository are:{}\".format(contributors))\n",
    "\n",
    "\n",
    "            #Getting the dataframe consisting of all repositories related to the contributors\n",
    "            if len(contributors)==1:\n",
    "                query = \"SELECT * FROM gitdatam WHERE actor_login = %s \"\n",
    "                con_df = pd.read_sql(query, con=db,params=[contributors[0]])\n",
    "\n",
    "            else:\n",
    "                contributors_t = tuple(contributors)\n",
    "                query = \"SELECT * FROM gitdatam WHERE actor_login IN {}\".format(contributors_t)\n",
    "                con_df = pd.read_sql(query, con=db)\n",
    "\n",
    "\n",
    "            con_df.head()\n",
    "\n",
    "            # Let df contain all the data which has only contributors related data\n",
    "            #find all the repos for which these actor_logins(contributors for current repository) have made a pull request and it is merged\n",
    "            from collections import defaultdict\n",
    "            contributors_repos= defaultdict(list)\n",
    "            repo_list=[]\n",
    "            for actor in contributors:\n",
    "                repos=[]\n",
    "                repos=con_df.loc[(con_df['type']==\"PullRequestEvent\")&(con_df['payload_pull_request_merged']==\"TRUE\")&(con_df['actor_login']==actor)].repo_name.tolist()\n",
    "                repo_list.extend(repos)\n",
    "                #import pdb; pdb.set_trace()\n",
    "                repos=list(set(repos))\n",
    "                repos.remove(focal_repository)\n",
    "                contributors_repos[actor]=repos\n",
    "            repo_list=list(set(repo_list))\n",
    "\n",
    "            #for key,value in contributors_repos.items():\n",
    "               # print(key,value)\n",
    "\n",
    "\n",
    "\n",
    "            # Getting the number of repositories where each contributor  of focal rep is also a contributor to other repos\n",
    "            # for key,value in contributors_repos.items():\n",
    "            #     print(key,len(value))\n",
    "\n",
    "            # function to return if the given single_contributor is a core_contributor or no\n",
    "            def core_contributors_bool_fun(unique_contributors, single_contributor, Main_df):\n",
    "                # Showing the push events by all the contributors to dynamo-easy repository by putting them in a dataframe\n",
    "                Contributors_df = pd.DataFrame()\n",
    "                Contributors_df = Main_df.loc[(df['type'] == \"PushEvent\") & (Main_df.actor_login.isin(unique_contributors))].copy()\n",
    "\n",
    "                # Finding the number of counts made by the single contributor\n",
    "                single_contributors_push_count = Contributors_df.loc[Contributors_df['actor_login'] == single_contributor].id.count()\n",
    "\n",
    "                # finding out the number of pushes of all the contributors for dynamo-easy repositor\n",
    "                Total_pushes_count = Contributors_df.id.count()\n",
    "\n",
    "                # Average of all the pushes by the contributors\n",
    "                Average_pushes = Total_pushes_count / len(unique_contributors)\n",
    "\n",
    "                # Compare the average number of pushes of all the contributors to number of pushes to individual contributors in\n",
    "                # unique contributors list\n",
    "\n",
    "\n",
    "                if single_contributors_push_count > Average_pushes:\n",
    "                        decider = True\n",
    "                else:\n",
    "                        decider = False\n",
    "\n",
    "                return decider\n",
    "\n",
    "\n",
    "            #Getting all the repos for contributed by the contributors\n",
    "            if len(repo_list)==0:\n",
    "                D=\"NaN\"\n",
    "                Parameters=[D,len(contributors),len(core_contributors_main)]\n",
    "                return Parameters\n",
    "            if len(repo_list)==1:\n",
    "                query = \"SELECT * FROM gitdatam WHERE repo_name = %s \"\n",
    "                repo_all = pd.read_sql(query, con=db,params=[repo_list[0]])\n",
    "\n",
    "            else:\n",
    "                repo_t = tuple(repo_list)\n",
    "                query = \"SELECT * FROM gitdatam WHERE repo_name IN {}\".format(repo_t)\n",
    "                repo_all = pd.read_sql(query, con=db)\n",
    "\n",
    "            repo_all.head()\n",
    "\n",
    "\n",
    "            # Creating a dictionary of core_contributor_repos consisting of core contributor as key and the list of their\n",
    "            # repositories as values\n",
    "            def core_contributors_repo_dict_fun(contributors_repos,repo_all):\n",
    "                from collections import defaultdict\n",
    "                #import pdb; pdb.set_trace()\n",
    "                core_contributors_repos = defaultdict(list)\n",
    "                core_repos = []\n",
    "                unique_contributors_temp = []\n",
    "\n",
    "                for key, value in contributors_repos.items():\n",
    "                    for repo in value:\n",
    "                        # Filtering only the entries where the repo_name is repo for which type is push, fork or pull request and storing them in a new dataframe\n",
    "                        repo_df = repo_all.loc[repo_all['repo_name'] == repo]\n",
    "                        unique_contributors_temp = contributors_fun(repo_df)\n",
    "                        if unique_contributors_temp != []:\n",
    "                            decider = core_contributors_bool_fun(unique_contributors_temp, key, repo_df)\n",
    "                            if decider == True:\n",
    "                                core_repos.append(repo)\n",
    "                    if core_repos != []:\n",
    "                        core_repos = list(set(core_repos))\n",
    "\n",
    "                        core_contributors_repos[key] = core_repos\n",
    "                    core_repos = []\n",
    "\n",
    "                return core_contributors_repos\n",
    "\n",
    "\n",
    "\n",
    "            # calling the function core_contributors_repo_dict_fun function\n",
    "            core_contributors_repos=core_contributors_repo_dict_fun(contributors_repos,repo_all)\n",
    "            #print(core_contributors_repos)\n",
    "\n",
    "\n",
    "            #making a list of all the keys(cc's in core_contributors_repos)\n",
    "            cc_list_other=[]\n",
    "            for key,value in core_contributors_repos.items():\n",
    "                cc_list_other.append(key)\n",
    "            #print(cc_list_other)\n",
    "\n",
    "            #getting the all the data related to the core contributors in the core_contributors_repos into the data frame\n",
    "            if len(cc_list_other)==0:\n",
    "                D=\"NaN\"\n",
    "                Parameters=[D,len(contributors),len(core_contributors_main)]\n",
    "                return Parameters\n",
    "            if len(cc_list_other)==1:\n",
    "                query = \"SELECT * FROM gitdatam WHERE actor_login = %s \"\n",
    "                cc_df_other = pd.read_sql(query, con=db,params=[cc_list_other[0]])\n",
    "\n",
    "            else:\n",
    "                cc_list_other_t = tuple(cc_list_other)\n",
    "                query = \"SELECT * FROM gitdatam WHERE actor_login IN {}\".format(cc_list_other_t)\n",
    "                cc_df_other = pd.read_sql(query, con=db)\n",
    "\n",
    "\n",
    "            cc_df_other.head()\n",
    "\n",
    "\n",
    "            # function to get decide if a cc has forked current repository in the active period of a repo\n",
    "            #pass the cc, focal repository(current_repo), main_repo(repo for which the cc has worked during the active period)\n",
    "            def reference_repos_bool(Core_contributor,current_repo, main_repo, Main_df):\n",
    "                # making a data frame which has only the entries of the core_contributor and the main_repo\n",
    "                core_df=Main_df.loc[(Main_df.actor_login == Core_contributor)&(Main_df.repo_name == main_repo) & (Main_df.type== \"PushEvent\")].copy()\n",
    "                # Getting the  date of the first push  on main_repo\n",
    "                start_date=core_df.created_at.min()\n",
    "                # Getting the date of the last push on main_repo\n",
    "                end_date=core_df.created_at.max()\n",
    "                # Getting the count of all the fork events on current_repo by the core_contributor\n",
    "                Fork_count_current_repo= Main_df.loc[(Main_df.actor_login == Core_contributor) & (Main_df.repo_name == current_repo)&(Main_df.created_at.between(start_date,end_date))&(Main_df.type==\"ForkEvent\")].id.count()\n",
    "\n",
    "                if Fork_count_current_repo != 0:\n",
    "                    decider=True\n",
    "                else:\n",
    "                    decider=False\n",
    "                return decider\n",
    "\n",
    "\n",
    "            # checking every cc in the main_repos from core_contributors_repos if he has forked current repo in the active period\n",
    "            def subsequent_work_fun(current_repo,core_contributors_repos):\n",
    "                subsequent_work=[]\n",
    "                for key,value in core_contributors_repos.items():\n",
    "                    for repo in value:\n",
    "                        decider = reference_repos_bool(key,current_repo, repo, cc_df_other)\n",
    "                        if decider==True:\n",
    "                            subsequent_work.append(repo)\n",
    "                        else:\n",
    "                            continue\n",
    "                subsequent_work=list(set(subsequent_work))\n",
    "                return subsequent_work\n",
    "\n",
    "\n",
    "            #calling the function to get the subsequent work\n",
    "            subsequent_work=subsequent_work_fun(focal_repository,core_contributors_repos)\n",
    "            #print(\"The susequent work citing focal repository are {}\".format(subsequent_work))\n",
    "\n",
    "            # getting the records containing all the subsequent work\n",
    "            if len(subsequent_work)==0:\n",
    "                D=\"NaN\"\n",
    "                Parameters=[D,len(contributors),len(core_contributors_main)]\n",
    "                return Parameters\n",
    "            if len(subsequent_work)==1:\n",
    "                subsequent_work_t=(subsequent_work[0])\n",
    "                query = 'SELECT * FROM gitdatam WHERE repo_name =%s'\n",
    "                sub_df = pd.read_sql(query, con=db, params=[subsequent_work_t])\n",
    "            else:\n",
    "                subsequent_work_t = tuple(subsequent_work)\n",
    "                query = \"SELECT * FROM gitdatam WHERE repo_name IN {}\".format(subsequent_work_t)\n",
    "                sub_df = pd.read_sql(query, con=db)\n",
    "            sub_df.head()\n",
    "\n",
    "\n",
    "            # Function to get the contributors when repo is specified\n",
    "            # pass the dataframe into the fuction containing all the types and repositories\n",
    "            def contributors_repo_fun(df,repos_name):\n",
    "                #creating a new data frame to store the subseted data(data pertaining a single repository and reponame\n",
    "                Main_df=df.loc[(df['repo_name']==repos_name)].copy()\n",
    "                Contributors=[]\n",
    "                Contributors=Main_df.loc[(Main_df['type']==\"PullRequestEvent\")&(Main_df['payload_pull_request_merged']==\"TRUE\")].actor_login.tolist()\n",
    "                unique_contributors= set(Contributors)\n",
    "                return unique_contributors\n",
    "\n",
    "\n",
    "            from collections import defaultdict\n",
    "            cc_sub=[]\n",
    "            repo_core_contributor = defaultdict(list)\n",
    "            for repo in subsequent_work:\n",
    "                unique_contributors_temp=contributors_repo_fun(sub_df,repo)\n",
    "                core_contributors_temp=core_contributors_fun(unique_contributors_temp,sub_df)\n",
    "                if core_contributors_temp!= []:\n",
    "                    repo_core_contributor[repo]=core_contributors_temp\n",
    "\n",
    "            for key,value in repo_core_contributor.items():\n",
    "                #print(key)\n",
    "                #print(value)\n",
    "                cc_sub.extend(value)\n",
    "\n",
    "            # printing all the core-contributors from repo_core_contributor\n",
    "            #print(list(set(cc_sub)))\n",
    "\n",
    "            # Getting the data frame containing the above cc's \n",
    "            #import pdb; pdb.set_trace()\n",
    "            if len(cc_sub)==0 or len(reference_repos_list)==0:\n",
    "                D=\"NaN\"\n",
    "                D=\"NaN\"\n",
    "                Parameters=[D,len(contributors),len(core_contributors_main)]\n",
    "                return Parameters\n",
    "\n",
    "            if len(cc_sub)==1 and len(reference_repos_list)==1:\n",
    "                cc_sub_t = tuple(cc_sub)+(\"\",)\n",
    "                reference_repos_list_t = tuple(reference_repos_list)+(\"\",)\n",
    "\n",
    "            elif len(cc_sub)>1 and len(reference_repos_list)==1:\n",
    "                cc_sub_t = tuple(cc_sub)\n",
    "                reference_repos_list_t = tuple(reference_repos_list)+(\"\",)\n",
    "            elif len(cc_sub)==1 and len(reference_repos_list)>1:\n",
    "                cc_sub_t = tuple(cc_sub)+(\"\",)\n",
    "                reference_repos_list_t = tuple(reference_repos_list)\n",
    "            else:\n",
    "                cc_sub_t = tuple(cc_sub)\n",
    "                reference_repos_list_t = tuple(reference_repos_list)\n",
    "\n",
    "            query = \"SELECT * FROM gitdatam WHERE actor_login IN {} OR repo_name IN {}\".format(cc_sub_t,reference_repos_list_t)\n",
    "            cc_sub_df = pd.read_sql(query, con=db)\n",
    "            cc_sub_df.head()\n",
    "\n",
    "            #  Check if any of these core-contributors have forked any of the reference repositories in their active period.\n",
    "            Subsequent_work_both = []\n",
    "            for key, value in repo_core_contributor.items():\n",
    "                for cc in value:\n",
    "                    if reference_repos_list != []:\n",
    "                        for ref_repo in reference_repos_list:\n",
    "                            decider = reference_repos_bool(cc, ref_repo, key, cc_sub_df)\n",
    "                            if decider == True:\n",
    "                                Subsequent_work_both.append(key)\n",
    "            Subsequent_work_both = list(set(Subsequent_work_both))\n",
    "\n",
    "            print(\"The Subsequent work citing both the references and the focal repository are {}\".format(Subsequent_work_both))\n",
    "            subsequent_work_only=set(subsequent_work)-set(Subsequent_work_both)\n",
    "            subsequent_work_only=list(subsequent_work_only)\n",
    "\n",
    "            #print(\"The Subsequent work citing only the focal repository are {}\".format(subsequent_work_only))\n",
    "\n",
    "\n",
    "            ni= len(set(subsequent_work_only))\n",
    "            nj=len(set(Subsequent_work_both))\n",
    "\n",
    "            if (ni-nj)==0:\n",
    "                print(\"The disruption value for {} is {}\".format(focal_repository,(ni-nj)))\n",
    "                D=0\n",
    "                Parameters=[D,len(contributors),len(core_contributors_main)]\n",
    "                return Parameters\n",
    "            else:\n",
    "                if len(reference_repos_list)==1:\n",
    "                    reference_repos_list_t = tuple(reference_repos_list)+(\"\",)\n",
    "                else:\n",
    "                    reference_repos_list_t = tuple(reference_repos_list)\n",
    "\n",
    "\n",
    "                query = \"SELECT DISTINCT * FROM gitdatam WHERE type= 'ForkEvent' AND repo_name IN {}\".format(reference_repos_list_t)\n",
    "                fork_df = pd.read_sql(query, con=db)\n",
    "                fork_df.head()\n",
    "                #Getting only the actors who forked the reference repositories\n",
    "                actors= fork_df.actor_login.tolist()\n",
    "                actors=list(set(actors))\n",
    "                #print(\"The actors who forked reference repository are:{}\".format(actors))\n",
    "                print(\"The length of the actors are{}\".format(len(actors)))\n",
    "                # Getting the actors data into the dataframe\n",
    "                #actors=[\"spatchcock\",\"bensie\"]\n",
    "                if len(actors)==0:\n",
    "                    D=\"NaN\"\n",
    "                    Parameters=[D,len(contributors),len(core_contributors_main)]\n",
    "                    return Parameters\n",
    "                if len(actors)==1:\n",
    "                    actors_t = tuple(actors)+(\"\",)\n",
    "                else:\n",
    "                    actors_t = tuple(actors)\n",
    "                query = \"SELECT DISTINCT * FROM gitdatam WHERE actor_login IN {}\".format(actors_t)\n",
    "                actors_df = pd.read_sql(query, con=db)\n",
    "                actors_df.head()\n",
    "                # step 3: Get all repositories to which these actors are contributors\n",
    "                # function to get the contributors_repos dict, pass the dataframe and the actors\n",
    "                #def contributors_actor_fun(df,actors):\n",
    "                #import pdb; pdb.set_trace()\n",
    "            #         from collections import defaultdict\n",
    "            #         contributors_repos = defaultdict(list)\n",
    "            #         for actor in actors:\n",
    "            #             repo_list=df.loc[(df['type']==\"PullRequestEvent\")&(df['payload_pull_request_merged']==\"TRUE\")&(df['actor_login']==actor)].repo_name.tolist()\n",
    "            #             repo_list=list(set(repo_list))\n",
    "            #             if repo_list!=[]:\n",
    "            #                 contributors_repos[actor]=repo_list\n",
    "            #         return contributors_repos\n",
    "                def contributors_actor_fun(df,actor):\n",
    "                    #import pdb; pdb.set_trace()\n",
    "                    from collections import defaultdict\n",
    "                    contributors_repos = defaultdict(list)\n",
    "                    repo_list=df.loc[(df['type']==\"PullRequestEvent\")&(df['payload_pull_request_merged']==\"TRUE\")&(df['actor_login']==actor)].repo_name.tolist()\n",
    "                    repo_list=list(set(repo_list))\n",
    "                    if repo_list!=[]:\n",
    "                        contributors_repos[actor]=repo_list\n",
    "                    #print(len(contributors_repos))\n",
    "                    return contributors_repos\n",
    "\n",
    "\n",
    "                # calling the function to get the contributors_repos dict based on the actors\n",
    "                contributors_repos_last= pd.Series(actors).swifter.apply(lambda x:contributors_actor_fun(actors_df,x))\n",
    "                #contributors_repos_last=contributors_actor_fun(actors_df,actors)\n",
    "                contributors_repos_last=dict(contributors_repos_last)\n",
    "                #print(contributors_repos_last\n",
    "                repo_only_list=[]\n",
    "                for key,value in contributors_repos_last.items():\n",
    "                    repo_only_list.extend(value)\n",
    "                repo_only_list=list(set(repo_only_list))\n",
    "                #print(repo_only_list)\n",
    "                #Getting all the repos for contributed by the contributors\n",
    "                if len(repo_only_list)==0:\n",
    "                    D=\"NaN\"\n",
    "                    Parameters=[D,len(contributors),len(core_contributors_main)]\n",
    "                    return Parameters\n",
    "                if len(repo_only_list)==1:\n",
    "                    repo_only_list_t = tuple(repo_only_list)+(\"\",)\n",
    "                else:\n",
    "                    repo_only_list_t = tuple(repo_only_list)\n",
    "                query = \"SELECT * FROM gitdatam WHERE repo_name IN {}\".format(repo_only_list_t)\n",
    "                repo_all_last = pd.read_sql(query, con=db)\n",
    "                repo_all_last.head()\n",
    "                # step 4: get all the repositories to which these contributors are core-contributors\n",
    "                # Find out the core-contributors in the contributors_repos dictionary\n",
    "                core_contributors_repos_last = core_contributors_repo_dict_fun(contributors_repos_last,repo_all_last)\n",
    "                #print(core_contributors_repos_last)\n",
    "\n",
    "\n",
    "                #step 5: Getting the repositories that the core contributors in core_contributors_repos has forked reference repos\n",
    "                # while they were active on their repositories\n",
    "                from collections import defaultdict\n",
    "                reference_subsequent = defaultdict(list)\n",
    "                subsequent_only_reference=[]\n",
    "                for repo in reference_repos_list:\n",
    "                    temp_repos=subsequent_work_fun(repo,core_contributors_repos)\n",
    "                    reference_subsequent[repo]=temp_repos\n",
    "                    subsequent_only_reference.extend(temp_repos)\n",
    "                subsequent_only_reference=list(set(subsequent_only_reference))\n",
    "                #print(\"The repositories citing only the refernces are {}\".format(subsequent_only_reference))\n",
    "\n",
    "\n",
    "                ni= len(set(subsequent_work_only))\n",
    "                nj=len(set(Subsequent_work_both))\n",
    "                nk=len(set(subsequent_only_reference))\n",
    "\n",
    "                print(\"ni={}\".format(ni))\n",
    "\n",
    "                print(\"nj={}\".format(nj))\n",
    "\n",
    "                print(\"nk={}\".format(nk))\n",
    "\n",
    "                D=(ni-nj)/(ni+nj+nk)\n",
    "\n",
    "                print(\"The disruption value for {} is {}\".format(focal_repository,D))\n",
    "                ABC=[D,len(contributors),len(core_contributors_main)]\n",
    "                return ABC\n",
    "\n",
    "import MySQLdb\n",
    "import pandas as pd\n",
    "import swifter\n",
    "import xlsxwriter\n",
    "# reading excel sheet\n",
    "excel_df= pd.read_csv(\"search1.csv\")\n",
    "excel_df['D']=''\n",
    "excel_df['Contributors']=''\n",
    "excel_df['C_C']=''\n",
    "\n",
    "# Open database connection\n",
    "db = MySQLdb.connect(\"localhost\",\"root\",\"Root@123\",\"github\" )\n",
    "\n",
    "name_list=list(excel_df.Repositories)\n",
    "i=-1\n",
    "for i in range(1,len(name_list)):\n",
    "    focal_repository= name_list[i]\n",
    "    i=i+1\n",
    "    Parameter_list=get_disruption_value(focal_repository)\n",
    "    excel_df.loc[i, 'D'] = Parameter_list[0]\n",
    "    excel_df.loc[i, 'Contributors'] = Parameter_list[1]\n",
    "    excel_df.loc[i, 'C_C'] = Parameter_list[2]\n",
    "#     excel_df.to_excel(\"searchrepo.csv\")\n",
    "    \n",
    "    print(\"{},{}: {}\".format(i,focal_repository,Parameter_list[0]))\n",
    "\n",
    "excel_df.to_csv(\"search1_values.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
